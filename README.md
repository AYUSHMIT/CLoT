
## Creative Leap-of-Thought (CLoT)
[![paper](https://img.shields.io/badge/cs.CV-1111.11111-b31b1b?logo=arxiv&logoColor=red)](www.google.com)
[![page](https://img.shields.io/badge/Project_Page-CLoT-orange)](www.google.com)
</br>


<p align="center">
  <img src="image/logo2.png" width="550" height="150"> 
</p>

By [Shanshan Zhong](https://github.com/zhongshsh)<sup>* 1,2</sup> and [Zhongzhan Huang](https://dedekinds.github.io)<sup>* 1,2</sup> and [Shanghua Gao](https://shgao.site/)<sup>3</sup>  and [Wushao Wen](https://scholar.google.com/citations?user=FSnLWy4AAAAJ)<sup>2</sup> and [Liang Lin](http://www.linliang.net)<sup>2</sup>  </br> and [Marinka Zitnik](https://zitniklab.hms.harvard.edu/)<sup>3</sup> and [Pan Zhou](https://panzhous.github.io/)<sup>#1</sup>

<sup>1</sup> Sea AI Lab  <sup>2</sup> Sun Yat-sen University <sup>3</sup> Harvard University</br>
<sup>* </sup>Equal contribution <sup>#</sup>Corresponding author

This repository is the official codebase of "Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation" [[paper]](www.google.com). Click [[project page]](www.google.com) for more funny examples.



## ðŸ¤£ Introduction

**Semantic Understanding and Reasoning** adapter (SUR-adapter) for pre-trained **diffusion models** can acquire the powerful semantic understanding and reasoning capabilities from **large language models** to build a high-quality textual semantic representation for text-to-image generation. 

<p align="center">
  <img src="https://github.com/Qrange-group/RAS/assets/62104945/af863827-2ea4-45cb-b3ed-2f98ba0e7d03">
</p>

## ðŸ˜† News


2023/10/20 - We have provided an example checkpoint of SUR-adapter [[Google Drive](https://drive.google.com/drive/folders/1UyC9_AqTezmHXmj4dh0A-9RBKKx_JmJZ?usp=share_link)]. Please try it! 

2023/08/19 - We have provided the data scraping code for Civitai. Please take a look at [processing](https://github.com/Qrange-group/SUR-adapter/blob/main/data_collect/processing.ipynb).

## ðŸ˜‚ TODO

- [x] data collection script
- [x] pretrain model
- [ ] dataset


## ðŸ˜„ Citation

```
@misc{zhong2023clot,
  title={Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation},
  author={Zhong, Shanshan and Huang, Zhongzhan and Gao, Shanghua and Wen, Weushao and Lin, Liang and Zitnik, Marinka and Zhou, Pan},
  booktitle={arxiv},
  year={2023}
}
```
